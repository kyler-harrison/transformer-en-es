{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5e337b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "\n",
    "import preprocess as prp\n",
    "from transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68d84758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602f0a9",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e45cd837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and word2vec embeddings\n",
    "df = pd.read_csv(\"data/en_es_reduced_data.csv\")\n",
    "en_vec_df = pd.read_csv(\"data/cc.en.300.reduced.csv\")\n",
    "es_vec_df = pd.read_csv(\"data/cc.es.300.reduced.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fc94c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  spanish\n",
       "0     Go.      Ve.\n",
       "1     Go.    Vete.\n",
       "2     Go.    Vaya.\n",
       "3     Go.  Váyase.\n",
       "4     Hi.    Hola."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f3990c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>[0.1250 -0.1079 0.0245 -0.2529 0.1057 -0.0184 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>[-0.0517 0.0740 -0.0131 0.0447 -0.0343 0.0212 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>[0.0342 -0.0801 0.1162 -0.3968 -0.0147 -0.0533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>[0.0082 -0.0899 0.0265 -0.0086 -0.0609 0.0068 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>[0.0047 0.0281 -0.0296 -0.0108 -0.0620 -0.0532...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word                                             vector\n",
       "0    ,  [0.1250 -0.1079 0.0245 -0.2529 0.1057 -0.0184 ...\n",
       "1  the  [-0.0517 0.0740 -0.0131 0.0447 -0.0343 0.0212 ...\n",
       "2    .  [0.0342 -0.0801 0.1162 -0.3968 -0.0147 -0.0533...\n",
       "3  and  [0.0082 -0.0899 0.0265 -0.0086 -0.0609 0.0068 ...\n",
       "4   to  [0.0047 0.0281 -0.0296 -0.0108 -0.0620 -0.0532..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0942db2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>[0.0547 0.0112 0.1910 0.0308 0.0414 0.0303 -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>[-0.0001 -0.0448 -0.2344 -0.0175 0.0231 -0.012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>[-0.0041 -0.0990 -0.0862 -0.0211 0.0899 -0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la</td>\n",
       "      <td>[0.0373 -0.0051 0.1350 0.0990 0.0181 0.0190 -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y</td>\n",
       "      <td>[-0.1160 -0.0598 -0.0966 0.0369 -0.0063 0.0431...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word                                             vector\n",
       "0   de  [0.0547 0.0112 0.1910 0.0308 0.0414 0.0303 -0....\n",
       "1    ,  [-0.0001 -0.0448 -0.2344 -0.0175 0.0231 -0.012...\n",
       "2    .  [-0.0041 -0.0990 -0.0862 -0.0211 0.0899 -0.020...\n",
       "3   la  [0.0373 -0.0051 0.1350 0.0990 0.0181 0.0190 -0...\n",
       "4    y  [-0.1160 -0.0598 -0.0966 0.0369 -0.0063 0.0431..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b16cfdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdfadsf']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_df = pd.DataFrame({\"word\": [\"asdfadsf\", \"apple\", \"your\"]})\n",
    "words_df[\"valid\"] = words_df[\"word\"].isin(en_vec_df[\"word\"])\n",
    "words_df[words_df[\"valid\"] == False][\"word\"].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be1bfbb",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d2dfc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert vector strings into lists of floats\n",
    "en_vec_df[\"vector\"] = prp.vec_str_to_list(en_vec_df, \"vector\")\n",
    "es_vec_df[\"vector\"] = prp.vec_str_to_list(es_vec_df, \"vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634d18cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>,</td>\n",
       "      <td>[0.125, -0.1079, 0.0245, -0.2529, 0.1057, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>[-0.0517, 0.074, -0.0131, 0.0447, -0.0343, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>[0.0342, -0.0801, 0.1162, -0.3968, -0.0147, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and</td>\n",
       "      <td>[0.0082, -0.0899, 0.0265, -0.0086, -0.0609, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>[0.0047, 0.0281, -0.0296, -0.0108, -0.062, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word                                             vector\n",
       "0    ,  [0.125, -0.1079, 0.0245, -0.2529, 0.1057, -0.0...\n",
       "1  the  [-0.0517, 0.074, -0.0131, 0.0447, -0.0343, 0.0...\n",
       "2    .  [0.0342, -0.0801, 0.1162, -0.3968, -0.0147, -0...\n",
       "3  and  [0.0082, -0.0899, 0.0265, -0.0086, -0.0609, 0....\n",
       "4   to  [0.0047, 0.0281, -0.0296, -0.0108, -0.062, -0...."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99205e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>[0.0547, 0.0112, 0.191, 0.0308, 0.0414, 0.0303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>[-0.0001, -0.0448, -0.2344, -0.0175, 0.0231, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>[-0.0041, -0.099, -0.0862, -0.0211, 0.0899, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>la</td>\n",
       "      <td>[0.0373, -0.0051, 0.135, 0.099, 0.0181, 0.019,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y</td>\n",
       "      <td>[-0.116, -0.0598, -0.0966, 0.0369, -0.0063, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word                                             vector\n",
       "0   de  [0.0547, 0.0112, 0.191, 0.0308, 0.0414, 0.0303...\n",
       "1    ,  [-0.0001, -0.0448, -0.2344, -0.0175, 0.0231, -...\n",
       "2    .  [-0.0041, -0.099, -0.0862, -0.0211, 0.0899, -0...\n",
       "3   la  [0.0373, -0.0051, 0.135, 0.099, 0.0181, 0.019,...\n",
       "4    y  [-0.116, -0.0598, -0.0966, 0.0369, -0.0063, 0...."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9de6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize strings into lists of tokens\n",
    "# see preprocess.py for function definition\n",
    "df[\"en_tokens\"] = df[\"english\"].apply(lambda sent: prp.sentence_to_tokens(sent, \"en\"))\n",
    "df[\"es_tokens\"] = df[\"spanish\"].apply(lambda sent: prp.sentence_to_tokens(sent, \"es\"))\n",
    "df[\"en_num_tokens\"] = df[\"en_tokens\"].apply(lambda x: len(x))\n",
    "df[\"es_num_tokens\"] = df[\"es_tokens\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db7bd903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>spanish</th>\n",
       "      <th>en_tokens</th>\n",
       "      <th>es_tokens</th>\n",
       "      <th>en_num_tokens</th>\n",
       "      <th>es_num_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Ve.</td>\n",
       "      <td>[&lt;s&gt;, go, ., &lt;e&gt;]</td>\n",
       "      <td>[&lt;s&gt;, ve, ., &lt;e&gt;]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vete.</td>\n",
       "      <td>[&lt;s&gt;, go, ., &lt;e&gt;]</td>\n",
       "      <td>[&lt;s&gt;, vete, ., &lt;e&gt;]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Vaya.</td>\n",
       "      <td>[&lt;s&gt;, go, ., &lt;e&gt;]</td>\n",
       "      <td>[&lt;s&gt;, vaya, ., &lt;e&gt;]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Váyase.</td>\n",
       "      <td>[&lt;s&gt;, go, ., &lt;e&gt;]</td>\n",
       "      <td>[&lt;s&gt;, váyase, ., &lt;e&gt;]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Hola.</td>\n",
       "      <td>[&lt;s&gt;, hi, ., &lt;e&gt;]</td>\n",
       "      <td>[&lt;s&gt;, hola, ., &lt;e&gt;]</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  english  spanish          en_tokens              es_tokens  en_num_tokens  \\\n",
       "0     Go.      Ve.  [<s>, go, ., <e>]      [<s>, ve, ., <e>]              4   \n",
       "1     Go.    Vete.  [<s>, go, ., <e>]    [<s>, vete, ., <e>]              4   \n",
       "2     Go.    Vaya.  [<s>, go, ., <e>]    [<s>, vaya, ., <e>]              4   \n",
       "3     Go.  Váyase.  [<s>, go, ., <e>]  [<s>, váyase, ., <e>]              4   \n",
       "4     Hi.    Hola.  [<s>, hi, ., <e>]    [<s>, hola, ., <e>]              4   \n",
       "\n",
       "   es_num_tokens  \n",
       "0              4  \n",
       "1              4  \n",
       "2              4  \n",
       "3              4  \n",
       "4              4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76b5f766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (111184, 6)\n",
      "num unique english sequences: (96092,)\n",
      "num unique spanish sequences: (106072,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"df shape: {df.shape}\")\n",
    "print(f\"num unique english sequences: {df['english'].unique().shape}\")\n",
    "print(f\"num unique spanish sequences: {df['spanish'].unique().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26815b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df shape: (97443, 6)\n",
      "num unique english sequences: (83385,)\n",
      "num unique spanish sequences: (92597,)\n"
     ]
    }
   ],
   "source": [
    "# reduce data to sequences of length < 11 (arbitrary)\n",
    "# (+2 for start/end tokens, +1 for spanish to account for double punctuation)\n",
    "max_tokens = 10\n",
    "df = df[(df[\"en_num_tokens\"] < (max_tokens + 3)) & (df[\"es_num_tokens\"] < (max_tokens + 4))]\n",
    "\n",
    "# a lot of words have multiple translations...\n",
    "# i don't think this is a big deal considering i just want to train a functional model\n",
    "print(f\"df shape: {df.shape}\")\n",
    "print(f\"num unique english sequences: {df['english'].unique().shape}\")\n",
    "print(f\"num unique spanish sequences: {df['spanish'].unique().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7924952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2)\n",
    "train_df.reset_index(inplace=True, drop=True)\n",
    "test_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c351fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (77954, 6)\n",
      "test shape: (19489, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train shape: {train_df.shape}\")\n",
    "print(f\"test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dff6b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_tuples(input_df, batch_size):\n",
    "    \"\"\"\n",
    "    Returns a list of tuples containing start/stop idx to grab from inp_df for a batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = input_df.shape[0]\n",
    "    num_batches = int(num_samples / batch_size)\n",
    "    batch_starts = np.arange(0, num_samples + 1, batch_size)    \n",
    "    return [(batch_starts[i], batch_starts[i + 1]) for i in range(len(batch_starts) - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc807a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch data\n",
    "batch_size = 256\n",
    "train_batch_tuples = get_batch_tuples(train_df, batch_size)\n",
    "test_batch_tuples = get_batch_tuples(test_df, batch_size)\n",
    "num_train_batches = len(train_batch_tuples)\n",
    "num_test_batches = len(test_batch_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d327b08",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa20459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_indices_to_tokens(pred_seqs, vec_df):\n",
    "    \"\"\"\n",
    "    Given list of lists containing indices of predicted tokens (output of get_predicted_token_indices()),\n",
    "    return list of lists where each sublist is now the actual string token corresponding to the input\n",
    "    index.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_preds = []\n",
    "    \n",
    "    for pred_seq in pred_seqs:\n",
    "        pred_tokens = []\n",
    "        \n",
    "        for pred_token in pred_seq:\n",
    "            word = vec_df.loc[pred_token][\"word\"]\n",
    "            pred_tokens.append(word)\n",
    "            \n",
    "            if (word == \"<e>\"):\n",
    "                break\n",
    "            \n",
    "        all_preds.append(pred_tokens)\n",
    "        \n",
    "    return all_preds\n",
    "\n",
    "\n",
    "def get_predicted_token_indices(predicted_batch):\n",
    "    \"\"\"\n",
    "    Returns a list of lists where each sublist contains the predicted token indices for each \n",
    "    predicted sequence in predicted_batch.\n",
    "    \"\"\"\n",
    "    \n",
    "    pred_seqs = []\n",
    "    \n",
    "    for batch in predicted_batch:\n",
    "        pred_seq = []\n",
    "        \n",
    "        for row in batch:\n",
    "            pred_seq.append(row.argmax().item())\n",
    "        \n",
    "        pred_seqs.append(pred_seq)\n",
    "        \n",
    "    return pred_seqs\n",
    "\n",
    "\n",
    "def save_model(model, model_name, epoch_train_losses, epoch_test_losses, epoch_bleu_scores):\n",
    "    \"\"\"\n",
    "    Save model and losses to files. Should be called after every training epoch.\n",
    "    Number of training epochs completed should be length of epoch_train_losses or \n",
    "    epoch_test_losses when model loaded back in. Could (should) save other training\n",
    "    params, but this is fine for now.\n",
    "    A .pt (actual model) and .json (metrics) file are created with model_name.\n",
    "    \n",
    "    returns None\n",
    "    \"\"\"\n",
    "    \n",
    "    # create paths\n",
    "    os.system(\"mkdir -p models\")\n",
    "    model_path = f\"models/{model_name}.pt\"\n",
    "    metrics_path = f\"models/{model_name}_metrics.json\"\n",
    "    \n",
    "    # save da model to pickle file\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # save metrics with corresponding model_path just in case i get confused later\n",
    "    metrics_dict = {\"epoch_train_losses\": epoch_train_losses, \"epoch_test_losses\": epoch_test_losses, \"epoch_bleu_scores\": epoch_bleu_scores, \"model_path\": model_path}\n",
    "    with open(metrics_path, \"w\") as fi: json.dump(metrics_dict, fi)\n",
    "\n",
    "\n",
    "def load_model(model, model_name):\n",
    "    \"\"\"\n",
    "    Load saved pytorch model and metrics created with save_model().\n",
    "    Must initialize model with same params as one you load from path.\n",
    "    \n",
    "    returns torch model, list of train losses, list of test losses, list of bleu scores\n",
    "    \"\"\"\n",
    "    \n",
    "    # create paths\n",
    "    model_path = f\"models/{model_name}.pt\"\n",
    "    metrics_path = f\"models/{model_name}_metrics.json\"\n",
    "    \n",
    "    # load model\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    \n",
    "    # load metrics\n",
    "    with open(metrics_path, \"r\") as fi: \n",
    "        metrics = json.load(fi)\n",
    "        \n",
    "    epoch_train_losses = metrics[\"epoch_train_losses\"]\n",
    "    epoch_test_losses = metrics[\"epoch_test_losses\"]\n",
    "    epoch_bleu_scores = metrics[\"epoch_bleu_scores\"]\n",
    "        \n",
    "    return model, epoch_train_losses, epoch_test_losses, epoch_bleu_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e03fb4",
   "metadata": {},
   "source": [
    "## Initialize transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4909f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoders): ModuleList(\n",
       "    (0): Encoder(\n",
       "      (Q_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (K_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (V_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (mha_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (layer_norm0): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff_linear0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (ff_relu): ReLU(inplace=True)\n",
       "      (ff_linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (layer_norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (decoders): ModuleList(\n",
       "    (0): Decoder(\n",
       "      (Q_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (K_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (V_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (mmha_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (layer_norm0): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (Q2_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (K2_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (V2_layer): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (mha_linear): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (layer_norm1): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "      (ff_linear0): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (ff_relu): ReLU(inplace=True)\n",
       "      (ff_linear1): Linear(in_features=300, out_features=300, bias=True)\n",
       "      (layer_norm2): LayerNorm((300,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (linear_layer): Linear(in_features=300, out_features=24672, bias=True)\n",
       "  (loss_criteria): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs will have shape (num_tokens, embedding_len)\n",
    "embedding_len = 300\n",
    "num_tokens = max(df[\"en_num_tokens\"].max(), df[\"es_num_tokens\"].max())  \n",
    "\n",
    "# NOTE <s> will never be in target, but its mapping index still exists\n",
    "# just to keep an annoying out-of-bounds error from happening later\n",
    "input_size = embedding_len\n",
    "output_size = es_vec_df.shape[0]\n",
    "\n",
    "# see \"attn is all you need\"\n",
    "N_layers = 1\n",
    "num_heads = 1\n",
    "version = \"NO_USE_IT\"\n",
    "\n",
    "# create torch model object\n",
    "new_model = True\n",
    "model_name = f\"tfrmr_{version}_N={N_layers}_h={num_heads}_B={batch_size}\"\n",
    "tfrmr = Transformer(input_size, output_size, N_layers, num_heads)\n",
    "\n",
    "if (new_model): \n",
    "    epoch_train_losses = []\n",
    "    epoch_test_losses = []\n",
    "    epoch_bleu_scores = []\n",
    "else:\n",
    "    tfrmr, epoch_train_losses, epoch_test_losses, epoch_bleu_scores = load_model(tfrmr, model_name)\n",
    "    \n",
    "tfrmr.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275fa38",
   "metadata": {},
   "source": [
    "## Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9d8f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(tfrmr, test_df, test_batch_tuple, en_vec_df, es_vec_df, batch_size, num_tokens, embedding_len, \n",
    "              output_size, pos_encoding_mat, start_token_vec, end_token_idx, device):\n",
    "    \"\"\"\n",
    "    This function generates a predicted sequence for each input sequence in input batch iteratively.\n",
    "    Used for making predictions after training (i.e. when the full target sequence is not available to \n",
    "    input to the decoder).\n",
    "    \n",
    "    returns a batch of predicted tfrmr outputs (not softmax probs) and a batch of one-hot target sequences\n",
    "    \"\"\"\n",
    "    \n",
    "    # get batch\n",
    "    test_start_idx = test_batch_tuple[0]\n",
    "    test_end_idx = test_batch_tuple[1]\n",
    "    test_batch = test_df[test_start_idx:test_end_idx]\n",
    "\n",
    "    # transform strings into tensors of embedded values\n",
    "    encoder_input = prp.embed_input_batch(test_batch, \"en_tokens\", en_vec_df, \"word\", \"vector\", embedding_len, num_tokens).to(device)\n",
    "\n",
    "    # positionally-encode\n",
    "    prp.pos_encode_batch(encoder_input, test_batch[\"en_num_tokens\"].values.tolist(), pos_encoding_mat)\n",
    "\n",
    "    # context generated for every matrix in batch, dont need to do again\n",
    "    encoder_context = tfrmr.forward(encoder_input, None, encoder_only=True)\n",
    "\n",
    "    # initialize decoder input for autoregressive prediction\n",
    "    decoder_input = torch.zeros(batch_size, num_tokens, embedding_len).to(device)\n",
    "\n",
    "    # holds final sequence prediction for each input sequence\n",
    "    predicted_seqs = torch.zeros(batch_size, num_tokens, output_size).to(device)\n",
    "\n",
    "    # iteratively generate predicted sequences for each input sequence\n",
    "    # SUB BATCH LOOP START\n",
    "    for batch_idx in range(batch_size):\n",
    "        done = False\n",
    "        token_idx = 0  # starting index of decoder input (0th predicted sequence will be put in decoder_input at token_idx=1 on next iteration)\n",
    "        decoder_input[batch_idx][token_idx] = start_token_vec  # initialize input with start token\n",
    "\n",
    "        # WHILE LOOP START\n",
    "        while ((not done) and (token_idx < (num_tokens - 1))):\n",
    "            # positional encoding performed row by row\n",
    "            decoder_input[batch_idx][token_idx] += pos_encoding_mat[token_idx]\n",
    "\n",
    "            # encoder_context is constant, decoder_input contains data up to before current token\n",
    "            # and is updated one row at a time with each prediction\n",
    "\n",
    "            # long statement. makes batches of single matrices so shapes work in transformer\n",
    "            prediction = tfrmr.forward(encoder_input[batch_idx].view(1, encoder_input.shape[1], \n",
    "                                          encoder_input.shape[2]), \n",
    "                                          decoder_input[batch_idx].view(1, decoder_input.shape[1], \n",
    "                                          decoder_input.shape[2]), \n",
    "                                          encoder_context=encoder_context[batch_idx].view(1, encoder_context.shape[1], \n",
    "                                          encoder_context.shape[2]), decoder_only=True)\n",
    "\n",
    "            # NOTE transformer output is not a softmax distribution across each row\n",
    "            # softmax is computed w loss calculation. but, the argmax before softmax\n",
    "            # will be the same as the argmax after softmax (just think about softmax eqn.)\n",
    "            max_token_idx = prediction[0][token_idx].argmax().item()\n",
    "            \n",
    "            # put prediction into final predicted sequence\n",
    "            predicted_seqs[batch_idx][token_idx] = prediction[0][token_idx]\n",
    "\n",
    "            # stop predicting if the end token has been predicted\n",
    "            if (max_token_idx == end_token_idx):        \n",
    "                done = True\n",
    "            else:\n",
    "                # for decoder's input: start token remains at index 0, this prediction goes to token_idx+1\n",
    "                # for predicted sequence: this prediction goes at token_idx (start token not included in final prediction)\n",
    "                token_vec = torch.tensor(es_vec_df.loc[max_token_idx, \"vector\"]).to(device)\n",
    "                decoder_input[batch_idx][token_idx + 1] = token_vec                \n",
    "\n",
    "            token_idx += 1\n",
    "\n",
    "            # WHILE LOOP END\n",
    "\n",
    "        # SUB BATCH LOOP END\n",
    "        \n",
    "    # create one-hot encoding of target sequences\n",
    "    targets_batch = prp.one_hot_batch(test_batch, es_vec_df, num_tokens, output_size, \"es_tokens\", \n",
    "                                      \"word\", smoothing=False).to(device)\n",
    "\n",
    "    return predicted_seqs, targets_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14050900",
   "metadata": {},
   "source": [
    "## Main train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a749a0e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EPOCH 0\n",
      "304 train batches of size 256 done in 20.179 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['¿', 'no', 'que', 'que', 'que', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['¿', 'no', 'que', 'que', 'que', 'que', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['¿', 'no', 'que', 'a', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['¿', 'no', 'que', 'que', 'que', 'que', 'de', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['¿', 'no', 'que', 'a', 'a', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.287 minutes\n",
      "mean train loss: 3.43720786038198\n",
      "mean test loss: 4.061335400531166\n",
      "mean 1-gram bleu score: 0.1878701879175349\n",
      "\n",
      "============================================================\n",
      "EPOCH 1\n",
      "304 train batches of size 256 done in 20.239 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'que', 'que', 'la', 'la', 'la', 'la', 'la', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'que', 'que', 'que', 'la', 'la', 'la', 'la', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'es', 'la', 'la', 'la', 'la', 'la', 'la', 'la', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'que', 'que', 'que', 'la', 'la', 'la', 'la', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'es', 'la', 'la', 'la', 'la', 'la', 'la', 'la', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.866 minutes\n",
      "mean train loss: 2.844319487872877\n",
      "mean test loss: 3.865519699297453\n",
      "mean 1-gram bleu score: 0.11556559402516557\n",
      "\n",
      "============================================================\n",
      "EPOCH 2\n",
      "304 train batches of size 256 done in 20.270 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'es', 'un', 'poco', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'es', 'la', 'la', 'la', 'la', 'la', 'la', 'la', 'mary', '.', 'de']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'es', 'un', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'es', 'un', 'poco', 'de', 'la', 'la', 'la', 'la', 'mary', '.', 'de']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'es', 'la', 'mary', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.420 minutes\n",
      "mean train loss: 2.7231533448947105\n",
      "mean test loss: 4.020317485457973\n",
      "mean 1-gram bleu score: 0.16037639802887263\n",
      "\n",
      "============================================================\n",
      "EPOCH 3\n",
      "304 train batches of size 256 done in 20.267 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['tom', 'no', 'tiene', 'a', 'mary', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'padre', 'en', 'la', 'casa', 'en', 'la', 'la', 'la', 'la', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['tom', 'es', 'es', 'un', 'poco', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['me', 'gusta', 'es', 'un', 'poco', 'de', 'la', 'la', 'la', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'gusta', 'a', 'mary', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.405 minutes\n",
      "mean train loss: 2.6127868741750717\n",
      "mean test loss: 4.069137061897077\n",
      "mean 1-gram bleu score: 0.17465466880407315\n",
      "\n",
      "============================================================\n",
      "EPOCH 4\n",
      "304 train batches of size 256 done in 20.293 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'se', 'gusta', 'a', 'la', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'padre', 'en', 'la', 'puerta', 'en', 'la', 'la', 'la', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['ella', 'es', 'es', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['me', 'gusta', 'es', 'un', 'poco', 'de', 'la', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'gusta', 'de', 'la', 'puerta', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.433 minutes\n",
      "mean train loss: 2.4940613382741024\n",
      "mean test loss: 3.9886549052439237\n",
      "mean 1-gram bleu score: 0.17221856046294556\n",
      "\n",
      "============================================================\n",
      "EPOCH 5\n",
      "304 train batches of size 256 done in 20.299 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'se', 'ha', 'estado', 'de', 'la', 'escuela', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'padre', 'en', 'la', 'puerta', 'en', 'la', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['el', 'hombre', 'es', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['no', 'me', 'gusta', 'un', 'poco', 'de', 'la', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'le', 'gusta', 'de', 'la', 'puerta', '.', '<e>']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 test batches of size 256 done in 4.404 minutes\n",
      "mean train loss: 2.4148699288305484\n",
      "mean test loss: 4.012906105894792\n",
      "mean 1-gram bleu score: 0.1731450253790133\n",
      "\n",
      "============================================================\n",
      "EPOCH 6\n",
      "304 train batches of size 256 done in 20.314 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'le', 'gusta', 'a', 'la', 'puerta', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'padre', 'en', 'la', 'vida', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['el', 'hombre', 'es', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['no', 'me', 'gusta', 'de', 'la', 'casa', 'de', 'la', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'le', 'gusta', 'de', 'la', 'puerta', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.447 minutes\n",
      "mean train loss: 2.3533612928892436\n",
      "mean test loss: 3.9354502370482995\n",
      "mean 1-gram bleu score: 0.17244244958068472\n",
      "\n",
      "============================================================\n",
      "EPOCH 7\n",
      "304 train batches of size 256 done in 20.310 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'le', 'gusta', 'a', 'la', 'puerta', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'padre', 'en', 'mi', 'padre', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['el', 'hombre', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', 'de', 'la', 'escuela', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'le', 'gusta', 'a', 'mary', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.441 minutes\n",
      "mean train loss: 2.301066259804525\n",
      "mean test loss: 3.9269492688931917\n",
      "mean 1-gram bleu score: 0.17897166616551682\n",
      "\n",
      "============================================================\n",
      "EPOCH 8\n",
      "304 train batches of size 256 done in 20.350 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'la', 'puerta', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'perro', 'en', 'mi', 'padre', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['hay', 'es', 'muy', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', 'de', 'la', 'habitación', 'de', 'la', 'casa', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'ha', 'estado', 'de', 'la', 'escuela', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.468 minutes\n",
      "mean train loss: 2.2544781204901243\n",
      "mean test loss: 3.886693841532657\n",
      "mean 1-gram bleu score: 0.17526729691575518\n",
      "\n",
      "============================================================\n",
      "EPOCH 9\n",
      "304 train batches of size 256 done in 20.341 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'su', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'perro', 'en', 'la', 'habitación', 'de', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['hay', 'es', 'muy', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', 'de', 'la', 'habitación', 'de', 'la', 'noche', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'ha', 'estado', 'de', 'la', 'puerta', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.480 minutes\n",
      "mean train loss: 2.213942569337393\n",
      "mean test loss: 3.873311387865167\n",
      "mean 1-gram bleu score: 0.17332231681274818\n",
      "\n",
      "============================================================\n",
      "EPOCH 10\n",
      "304 train batches of size 256 done in 20.358 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'su', 'nombre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'perro', 'se', 'puso', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['hay', 'es', 'muy', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', 'de', 'la', 'verdad', 'de', 'la', 'noche', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'sentó', 'el', 'libro', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.463 minutes\n",
      "mean train loss: 2.1772353500127792\n",
      "mean test loss: 3.852936393336246\n",
      "mean 1-gram bleu score: 0.17379706205624124\n",
      "\n",
      "============================================================\n",
      "EPOCH 11\n",
      "304 train batches of size 256 done in 20.405 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'su', 'nombre', 'de', 'su', 'madre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'perro', 'se', 'puso', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['por', 'favor', ',', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', 'de', 'la', 'noche', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'sentó', 'el', 'libro', '.', '<e>']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 test batches of size 256 done in 4.478 minutes\n",
      "mean train loss: 2.1442450935903348\n",
      "mean test loss: 3.8279180965925517\n",
      "mean 1-gram bleu score: 0.17040263242660728\n",
      "\n",
      "============================================================\n",
      "EPOCH 12\n",
      "304 train batches of size 256 done in 20.350 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'la', 'puerta', 'de', 'su', 'madre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'perro', 'se', 'puso', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['hay', 'que', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', 'de', 'la', 'noche', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'sentó', 'el', 'lunes', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.477 minutes\n",
      "mean train loss: 2.1146661650977636\n",
      "mean test loss: 3.8366460737429167\n",
      "mean 1-gram bleu score: 0.17403199052648352\n",
      "\n",
      "============================================================\n",
      "EPOCH 13\n",
      "304 train batches of size 256 done in 20.370 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'la', 'puerta', 'de', 'su', 'madre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'hombre', 'se', 'puso', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['¡', 'qué', 'es', 'tan', 'alto', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', ',', 'pero', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'sentó', 'el', 'lunes', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.511 minutes\n",
      "mean train loss: 2.087719179689884\n",
      "mean test loss: 3.7792382114811947\n",
      "mean 1-gram bleu score: 0.17337322228375437\n",
      "\n",
      "============================================================\n",
      "EPOCH 14\n",
      "304 train batches of size 256 done in 20.380 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'la', 'puerta', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'niño', 'se', 'quedó', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['¡', 'qué', 'es', 'tan', 'alto', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', ',', 'por', 'la', 'noche', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'sentó', 'el', 'lunes', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.470 minutes\n",
      "mean train loss: 2.0624211548190368\n",
      "mean test loss: 3.8050384427371777\n",
      "mean 1-gram bleu score: 0.17697162344789097\n",
      "\n",
      "============================================================\n",
      "EPOCH 15\n",
      "304 train batches of size 256 done in 20.362 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'la', 'puerta', 'de', 'su', 'madre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'niño', 'se', 'quedó', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['¡', 'qué', ',', 'ella', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', ',', 'por', 'la', 'noche', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'sentó', 'el', 'lunes', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.489 minutes\n",
      "mean train loss: 2.040201161252825\n",
      "mean test loss: 3.7869856577170524\n",
      "mean 1-gram bleu score: 0.18030728441905844\n",
      "\n",
      "============================================================\n",
      "EPOCH 16\n",
      "304 train batches of size 256 done in 20.367 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'tiene', 'a', 'la', 'escuela', 'de', 'su', 'familia', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'niño', 'se', 'quedó', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['por', 'favor', ',', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', ',', 'pero', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'quedó', 'el', 'pelo', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.484 minutes\n",
      "mean train loss: 2.018877991328114\n",
      "mean test loss: 3.7586829442726937\n",
      "mean 1-gram bleu score: 0.17661229531042805\n",
      "\n",
      "============================================================\n",
      "EPOCH 17\n",
      "304 train batches of size 256 done in 20.363 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'le', 'aconsejó', 'a', 'la', 'escuela', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'hombre', 'se', 'quedó', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['por', 'favor', ',', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', ',', 'pero', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'sentó', 'el', 'lunes', '.', '<e>']\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 test batches of size 256 done in 4.468 minutes\n",
      "mean train loss: 1.9979269469254894\n",
      "mean test loss: 3.791279375553131\n",
      "mean 1-gram bleu score: 0.17753994502435988\n",
      "\n",
      "============================================================\n",
      "EPOCH 18\n",
      "304 train batches of size 256 done in 20.369 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'le', 'aconsejó', 'a', 'la', 'escuela', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'coche', 'se', 'quedó', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['hay', ',', 'ella', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', ',', 'pero', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'quedó', 'el', 'pelo', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.482 minutes\n",
      "mean train loss: 1.9777512005285214\n",
      "mean test loss: 3.7336958270323906\n",
      "mean 1-gram bleu score: 0.17664769890652832\n",
      "\n",
      "============================================================\n",
      "EPOCH 19\n",
      "304 train batches of size 256 done in 20.369 minutes\n",
      "\n",
      "example predictions:\n",
      "english: ['<s>', 'she', 'used', 'to', 'play', 'tennis', 'with', 'him', '.', '<e>']\n",
      "spanish: ['ella', 'solía', 'jugar', 'al', 'tenis', 'con', 'él', '.', '<e>']\n",
      "predicted: ['ella', 'le', 'aconsejó', 'a', 'la', 'escuela', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'the', 'bus', 'stops', 'in', 'front', 'of', 'my', 'house', '.', '<e>']\n",
      "spanish: ['el', 'autobús', 'para', 'delante', 'de', 'mi', 'casa', '.', '<e>']\n",
      "predicted: ['el', 'coche', 'se', 'quedó', 'en', 'mi', 'padre', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'unfortunately', ',', 'she', 'is', 'absent', '.', '<e>']\n",
      "spanish: ['desafortunadamente', ',', 'ella', 'está', 'ausente', '.', '<e>']\n",
      "predicted: ['hay', ',', 'ella', 'es', 'muy', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'we', 'want', 'an', 'assistant', ',', 'preferably', 'someone', 'with', 'experience', '.', '<e>']\n",
      "spanish: ['buscamos', 'un', 'asistente', ',', 'preferiblemente', 'alguien', 'con', 'experiencia', '.', '<e>']\n",
      "predicted: ['tenemos', 'un', 'poco', ',', 'pero', ',', 'pero', '.', '<e>']\n",
      "\n",
      "english: ['<s>', 'tom', 'flirted', 'with', 'the', 'waitress', '.', '<e>']\n",
      "spanish: ['tom', 'coqueteó', 'con', 'la', 'mesera', '.', '<e>']\n",
      "predicted: ['tom', 'se', 'quedó', 'el', 'pelo', '.', '<e>']\n",
      "\n",
      "76 test batches of size 256 done in 4.495 minutes\n",
      "mean train loss: 1.9590213800731457\n",
      "mean test loss: 3.7373103154333016\n",
      "mean 1-gram bleu score: 0.17914003891604788\n",
      "\n",
      "20 epochs done in 496.036 minutes\n",
      "CPU times: user 8h 17min 44s, sys: 24min 46s, total: 8h 42min 31s\n",
      "Wall time: 8h 16min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "num_epochs = 20\n",
    "pos_encoding_mat = prp.gen_positional_encoding(num_tokens, embedding_len).to(device)\n",
    "start_token_vec = torch.tensor(es_vec_df[es_vec_df[\"word\"] == \"<s>\"][\"vector\"].item())\n",
    "end_token_idx = es_vec_df[es_vec_df[\"word\"] == \"<e>\"].index.item()\n",
    "\n",
    "# EPOCH LOOP START\n",
    "epoch_start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"EPOCH {epoch}\")\n",
    "    train_losses = []\n",
    "    \n",
    "    # BATCH LOOP START\n",
    "    batch_start_time = time.time()  \n",
    "    for batch_idx, batch_tuple in enumerate(train_batch_tuples):\n",
    "        # get batch\n",
    "        start_idx = batch_tuple[0]\n",
    "        end_idx = batch_tuple[1]\n",
    "        batch = train_df[start_idx:end_idx]\n",
    "        \n",
    "        # transform strings into tensors of embedded values\n",
    "        encoder_input = prp.embed_input_batch(batch, \"en_tokens\", en_vec_df, \"word\", \"vector\", embedding_len, num_tokens).to(device)\n",
    "        decoder_input = prp.embed_input_batch(batch, \"es_tokens\", es_vec_df, \"word\", \"vector\", embedding_len, num_tokens).to(device)\n",
    "        \n",
    "        # positionally-encode\n",
    "        prp.pos_encode_batch(encoder_input, batch[\"en_num_tokens\"].values.tolist(), pos_encoding_mat)\n",
    "        prp.pos_encode_batch(decoder_input, batch[\"es_num_tokens\"].values.tolist(), pos_encoding_mat)\n",
    "\n",
    "        # forward pass\n",
    "        fwd_out = tfrmr.forward(encoder_input, decoder_input)\n",
    "        \n",
    "        # create one-hot targets\n",
    "        targets = prp.one_hot_batch(batch, es_vec_df, num_tokens, output_size, \"es_tokens\", \"word\", \n",
    "                                    smoothing=True, smoothing_epsilon=0.1).to(device)\n",
    "        \n",
    "        # loss and backward pass\n",
    "        train_loss = tfrmr.calc_loss(fwd_out, targets)\n",
    "        tfrmr.backward()\n",
    "        train_losses.append(train_loss.item())\n",
    "        \n",
    "        # BATCH LOOP END  \n",
    "    \n",
    "    batch_stop_time = time.time()\n",
    "    print(f\"{num_train_batches} train batches of size {batch_size} done in {(batch_stop_time - batch_start_time) / 60:.3f} minutes\")\n",
    "    \n",
    "    mean_train_loss = np.mean(train_losses)\n",
    "    epoch_train_losses.append(mean_train_loss)\n",
    "    \n",
    "    # INFERENCE START\n",
    "    # perform inference (i.e. see how model performs on unseen test data)\n",
    "    inference_start_time = time.time()\n",
    "    test_losses = []\n",
    "    bleu_scores = []\n",
    "    example_idx = 0\n",
    "    num_examples = 5\n",
    "    \n",
    "    # TEST BATCH LOOP START\n",
    "    for test_batch_idx, test_batch_tuple in enumerate(test_batch_tuples):\n",
    "        # iteratively generate predicted sequences in each batch\n",
    "        predicted_seqs, targets_batch = inference(tfrmr, test_df, test_batch_tuple, en_vec_df, es_vec_df, \n",
    "                                                  batch_size, num_tokens, embedding_len, output_size, \n",
    "                                                  pos_encoding_mat, start_token_vec, end_token_idx, device)\n",
    "\n",
    "        # calculate loss w/o updating model params\n",
    "        # NOTE that the .item() here is very important - saves a lot of internal torch autograd graph stuff in memory w/o\n",
    "        test_loss = tfrmr.calc_loss(predicted_seqs, targets_batch, test_loss=True).item()\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # calculate 1-gram bleu score\n",
    "        predicted_tokens = map_indices_to_tokens(get_predicted_token_indices(predicted_seqs), es_vec_df)\n",
    "        target_tokens = [seq[1:] for seq in test_df[test_batch_tuple[0]:test_batch_tuple[1]][\"es_tokens\"].values.tolist()]\n",
    "        bleu_score = corpus_bleu(target_tokens, predicted_tokens, weights=[1])\n",
    "        bleu_scores.append(bleu_score)\n",
    "        \n",
    "        # look at a few example predictions\n",
    "        if (test_batch_idx == example_idx):\n",
    "            en_input = test_df[test_batch_tuple[0]:test_batch_tuple[0] + num_examples][\"en_tokens\"].values.tolist()\n",
    "            print(\"\\nexample predictions:\")\n",
    "            \n",
    "            for idx in range(num_examples):\n",
    "                print(f\"english: {en_input[idx]}\")\n",
    "                print(f\"spanish: {target_tokens[idx]}\")\n",
    "                print(f\"predicted: {predicted_tokens[idx]}\\n\")\n",
    "        \n",
    "        # TEST BATCH LOOP END\n",
    "        \n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "    epoch_test_losses.append(mean_test_loss)\n",
    "    mean_bleu_score = np.mean(bleu_scores)\n",
    "    epoch_bleu_scores.append(mean_bleu_score)\n",
    "    inference_stop_time = time.time()\n",
    "    print(f\"{len(test_batch_tuples)} test batches of size {batch_size} done in {(inference_stop_time - inference_start_time) / 60:.3f} minutes\")\n",
    "    \n",
    "    # INFERENCE END\n",
    "    \n",
    "    print(f\"mean train loss: {mean_train_loss}\")\n",
    "    print(f\"mean test loss: {mean_test_loss}\")\n",
    "    print(f\"mean 1-gram bleu score: {mean_bleu_score}\\n\")\n",
    "    \n",
    "    # save model and metrics\n",
    "    save_model(tfrmr, model_name, epoch_train_losses, epoch_test_losses, epoch_bleu_scores)\n",
    "    \n",
    "    # EPOCH LOOP END\n",
    "    \n",
    "epoch_stop_time = time.time()\n",
    "print(f\"{num_epochs} epochs done in {(epoch_stop_time - epoch_start_time) / 60:.3f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4333c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfrmr-kernel",
   "language": "python",
   "name": "tfrmr-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
